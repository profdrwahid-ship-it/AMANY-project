# pages/5_Financial_Data.py
# Financial dashboard with:
# - Page-wide header (AMANY + full name + current datetime)
# - Robust header resolution (row2 -> row1 -> row3 -> Unnamed, unique)
# - Month index from column A (m/YYYY)
# - KPIs computed up to previous month end (exclude current/future months)
# - Safe PNG export (on-click, guarded)
# - Optional OLS trendline (only if statsmodels available)
# - Excel export with engine auto-detect; CSV ZIP fallback

import time
from datetime import datetime
import streamlit as st
import pandas as pd
import numpy as np
import gspread
from google.oauth2.service_account import Credentials
import plotly.graph_objects as go
import plotly.express as px
from io import BytesIO
import traceback

# Optional PNG export
try:
    import kaleido  # noqa: F401
    KALEIDO = True
except Exception:
    KALEIDO = False

# Optional OLS dependency
try:
    import statsmodels.api as sm  # noqa: F401
    HAS_SM = True
except Exception:
    HAS_SM = False

# Optional Cairo timezone
try:
    import pytz
    CAIRO_TZ = pytz.timezone("Africa/Cairo")
except Exception:
    CAIRO_TZ = None

# ---------------- Page config ----------------
st.set_page_config(page_title="AMANY - Ù„ÙˆØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©", layout="wide", page_icon="ğŸ’¡")

st.markdown("""
<style>
.stApp { background:#2e5ae8; }
h1,h2,h3 { color:#39ff14; }
.amany-header { text-align:center; margin: 8px 0 16px 0; }
.amany-title-short { font-size:36px; font-weight:900; letter-spacing:2px; color:#39ff14; }
.amany-title-full { font-size:18px; color:#f0f8ff; margin-top:4px; }
.amany-datetime { font-size:14px; color:#ddd; margin-top:6px; }
</style>
""", unsafe_allow_html=True)

# ---------------- Helpers ----------------
def now_cairo():
    return datetime.now(CAIRO_TZ) if CAIRO_TZ else datetime.now()

def month_start(dt: datetime) -> pd.Timestamp:
    return pd.Timestamp(year=dt.year, month=dt.month, day=1)

def prev_month_start(dt: datetime) -> pd.Timestamp:
    m = dt.month - 1 or 12
    y = dt.year if dt.month > 1 else dt.year - 1
    return pd.Timestamp(year=y, month=m, day=1)

def prev_month_end(dt: datetime) -> pd.Timestamp:
    pms = prev_month_start(dt)
    return pms + pd.offsets.MonthEnd(0)

def with_backoff(func, *args, **kwargs):
    for d in [0.5, 1, 2, 4, 8]:
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if "429" in str(e) or "Quota" in str(e):
                time.sleep(d); continue
            raise
    raise RuntimeError("Backoff retries exceeded.")

# ---------------- Spreadsheet ID ----------------
# ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Spreadsheet ID
SPREADSHEET_ID = ""
try:
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ID Ù…Ù† Ø§Ù„Ø£Ø³Ø±Ø§Ø± Ø£ÙˆÙ„Ø§Ù‹
    if "sheets" in st.secrets and "spreadsheet_id" in st.secrets["sheets"]:
        SPREADSHEET_ID = st.secrets["sheets"]["spreadsheet_id"]
    elif "spreadsheet_id" in st.secrets:
        SPREADSHEET_ID = st.secrets["spreadsheet_id"]
except Exception:
    pass

# Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ID ÙÙŠ Ø§Ù„Ø£Ø³Ø±Ø§Ø±ØŒ Ù†Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
if not SPREADSHEET_ID:
    SPREADSHEET_ID = st.text_input("Ø£Ø¯Ø®Ù„ Spreadsheet ID:", value="1lELs2hhkOnFVix8HSE4iHpw8r20RXnEMXK9uzHSbT6Y")

# ---------------- Page-wide header ----------------
_now = now_cairo().strftime("%Y-%m-%d %H:%M:%S")
st.markdown(f"""
<div class="amany-header">
  <div class="amany-title-short">AMANY</div>
  <div class="amany-title-full">AMANY â€“ Advanced Financial Dashboard</div>
  <div class="amany-datetime">{_now}</div>
</div>
""", unsafe_allow_html=True)

# ---------------- Settings ----------------
CONFIG_SHEET_NAME = "Config"
TOTALS_CONFIG_COLUMN = "Totals_KPIs"
ALERT_THRESHOLD = 20.0

# ---------------- Resources ----------------
@st.cache_resource(ttl=7200)
def get_spreadsheet(spreadsheet_id: str):
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© spreadsheet_id
        if not spreadsheet_id or not isinstance(spreadsheet_id, str):
            st.error("Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù„Ù ØºÙŠØ± ØµØ§Ù„Ø­")
            return None
            
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø£Ø³Ø±Ø§Ø±
        if "gcp_service_account" not in st.secrets:
            st.error("Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø£Ø³Ø±Ø§Ø±")
            return None
            
        creds_dict = st.secrets["gcp_service_account"]
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† creds_dict Ù‡Ùˆ Ù‚Ø§Ù…ÙˆØ³
        if not isinstance(creds_dict, dict):
            st.error("Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ ØºÙŠØ± ØµØ§Ù„Ø­Ø©")
            return None
            
        creds = Credentials.from_service_account_info(
            creds_dict,
            scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"],
        )
        client = gspread.authorize(creds)
        return with_backoff(client.open_by_key, spreadsheet_id)
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©: {e}")
        return None

@st.cache_data(ttl=900)
def list_worksheets(spreadsheet_id: str):
    if not spreadsheet_id:
        return []
        
    sh = get_spreadsheet(spreadsheet_id)
    if sh is None:
        return []
        
    try:
        return [ws.title for ws in with_backoff(sh.worksheets)]
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£ÙˆØ±Ø§Ù‚: {e}")
        return []

@st.cache_data(ttl=900)
def get_all_values(spreadsheet_id: str, worksheet_name: str):
    if not spreadsheet_id or not worksheet_name:
        return []
        
    sh = get_spreadsheet(spreadsheet_id)
    if sh is None:
        return []
        
    try:
        ws = with_backoff(sh.worksheet, worksheet_name.strip())
        return with_backoff(ws.get_all_values)
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† {worksheet_name}: {e}")
        return []

@st.cache_data(ttl=900)
def read_totals_list(spreadsheet_id: str):
    try:
        vals = get_all_values(spreadsheet_id, CONFIG_SHEET_NAME)
        if len(vals) < 2:
            return []
        header = [str(h).strip() for h in vals[0]]
        cfg = pd.DataFrame(vals[1:], columns=header)
        if TOTALS_CONFIG_COLUMN not in cfg.columns:
            return []
        return cfg[TOTALS_CONFIG_COLUMN].dropna().astype(str).str.strip().tolist()
    except Exception:
        return []

# ---------------- Header resolving ----------------
def make_headers_unique(headers: list) -> list:
    seen = {}
    out = []
    for h in headers:
        h = str(h)
        if h not in seen:
            seen[h] = 0
            out.append(h)
        else:
            seen[h] += 1
            out.append(f"{h}.{seen[h]}")
    return out

def resolve_headers_merged(row1: list, row2: list, row3: list) -> list:
    L = max(len(row1), len(row2), len(row3))
    tmp = []
    for j in range(L):
        a = str(row2[j]).strip() if j < len(row2) else ""
        b = str(row1[j]).strip() if j < len(row1) else ""
        c = str(row3[j]).strip() if j < len(row3) else ""
        if a:
            tmp.append(a)
        elif b:
            tmp.append(b)
        elif c:
            tmp.append(c)
        else:
            tmp.append("Unnamed")
    return make_headers_unique(tmp)

# ---------------- Parsing ----------------
def parse_sheet(all_values):
    if not all_values or len(all_values) < 1:
        st.warning("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ© Ø£Ùˆ ÙØ§Ø±ØºØ©")
        return pd.DataFrame(), [], []

    # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØµØ­ÙŠØ­
    st.write("### ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…:")
    st.write(f"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {len(all_values)}")
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØµÙ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
    header_row_idx = 0
    for i, row in enumerate(all_values[:3]):
        non_empty_cells = sum(1 for cell in row if str(cell).strip())
        st.write(f"Ø§Ù„ØµÙ {i}: {row[:5]}... (Ø®Ù„Ø§ÙŠØ§ ØºÙŠØ± ÙØ§Ø±ØºØ©: {non_empty_cells})")
        if non_empty_cells > len(row) * 0.5:  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø£ÙƒØ«Ø± Ù…Ù† 50% Ù…Ù† Ø§Ù„Ø®Ù„Ø§ÙŠØ§ ØºÙŠØ± ÙØ§Ø±ØºØ©
            header_row_idx = i
            break

    st.write(f"âœ… Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØµÙ {header_row_idx} ÙƒØ¹Ù†Ø§ÙˆÙŠÙ†")

    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØµÙ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ ÙƒØ¹Ù†Ø§ÙˆÙŠÙ†
    header_row = all_values[header_row_idx]
    data_rows = all_values[header_row_idx + 1:]
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†
    cleaned_headers = []
    for h in header_row:
        h_str = str(h).strip()
        if not h_str:
            h_str = f"Column_{len(cleaned_headers)+1}"
        cleaned_headers.append(h_str)
    
    # Ø¬Ø¹Ù„ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† ÙØ±ÙŠØ¯Ø©
    headers_resolved = make_headers_unique(cleaned_headers)
    st.write(f"Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {headers_resolved}")

    # Ø¥Ù†Ø´Ø§Ø¡ DataFrame
    raw_df = pd.DataFrame(data_rows, columns=headers_resolved)
    
    if raw_df.empty:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†")
        return pd.DataFrame(), header_row, data_rows

    st.write(f"ğŸ“Š Ø´ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {raw_df.shape}")

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„)
    if len(raw_df.columns) > 0:
        first_col = raw_df.columns[0]
        st.write(f"Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„: '{first_col}'")
        
        # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„
        date_samples = raw_df.iloc[:5, 0].tolist()
        st.write(f"Ø¹ÙŠÙ†Ø§Øª Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ÙˆÙ„: {date_samples}")

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¨Ù…Ø±ÙˆÙ†Ø©
        date_series = raw_df.iloc[:, 0].astype(str).str.strip()
        
        # Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
        dates = pd.to_datetime(date_series, errors='coerce')
        
        # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ØŒ Ø¬Ø±Ø¨ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        if dates.isna().any():
            st.write("ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¨ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø¨Ø¯ÙŠÙ„Ø©...")
            for fmt in ['%m/%Y', '%m-%Y', '%Y/%m', '%Y-%m', '%b %Y', '%B %Y']:
                mask = dates.isna()
                if mask.any():
                    try:
                        parsed = pd.to_datetime(date_series[mask], format=fmt, errors='coerce')
                        dates[mask] = parsed
                        st.write(f"   - ØªÙ†Ø³ÙŠÙ‚ {fmt}: Ù†Ø¬Ø­ ÙÙŠ {parsed.notna().sum()} ØµÙ")
                    except:
                        continue

        # Ø¥Ø°Ø§ Ø¨Ù‚ÙŠ Ù‡Ù†Ø§Ùƒ ØªÙˆØ§Ø±ÙŠØ® ÙØ§Ø±ØºØ©ØŒ Ø¥Ù†Ø´Ø§Ø¡ ØªÙˆØ§Ø±ÙŠØ® Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        if dates.isna().any():
            st.write("ğŸ“… Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙˆØ§Ø±ÙŠØ® Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ§Ø±ØºØ©...")
            base_date = pd.Timestamp('2020-01-01')
            na_count = dates.isna().sum()
            for i in range(len(dates)):
                if pd.isna(dates.iloc[i]):
                    dates.iloc[i] = base_date + pd.DateOffset(months=i)
            st.write(f"   - ØªÙ… ØªØ¹ÙŠÙŠÙ† {na_count} ØªØ§Ø±ÙŠØ® Ø§ÙØªØ±Ø§Ø¶ÙŠ")

        st.write(f"âœ… Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {dates.tolist()[:5]}...")

        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¥Ù„Ù‰ DataFrame
        proc = raw_df.copy()
        proc["__MonthDate__"] = dates
        proc["Month"] = date_series
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰
        numeric_cols = [col for col in proc.columns if col not in ['__MonthDate__', 'Month', first_col]]
        st.write(f"ğŸ”„ ØªÙ†Ø¸ÙŠÙ {len(numeric_cols)} Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠ...")
        
        clean_count = 0
        for col in numeric_cols:
            original_sample = proc[col].head(3).tolist()
            proc[col] = (proc[col].astype(str)
                         .str.replace(r'[,\s]', '', regex=True)  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ ÙˆØ§Ù„Ù…Ø³Ø§ÙØ§Øª
                         .str.replace('%', '', regex=False)
                         .replace(['', '-', 'â€”', 'N/A', 'n/a', 'NULL', 'null', 'None'], '0')
                         .replace(['NaN', 'nan', 'Infinity', 'inf'], '0'))
            
            # Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù‚Ù…
            proc[col] = pd.to_numeric(proc[col], errors='coerce').fillna(0)
            
            cleaned_sample = proc[col].head(3).tolist()
            if any(x != 0 for x in proc[col]):
                clean_count += 1
            
            st.write(f"   - {col}: {original_sample} â†’ {cleaned_sample}")

        st.write(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ {clean_count}/{len(numeric_cols)} Ø¹Ù…ÙˆØ¯ Ø¨Ù†Ø¬Ø§Ø­")

        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªÙˆØ§Ø±ÙŠØ® ØµØ§Ù„Ø­Ø© ÙˆØ§Ù„ÙØ±Ø²
        proc = proc.dropna(subset=['__MonthDate__']).set_index('__MonthDate__').sort_index()

        st.success(f"ğŸ‰ ØªÙ… ØªØ­Ù„ÙŠÙ„ {len(proc)} ØµÙ Ùˆ {len(proc.columns)} Ø¹Ù…ÙˆØ¯ Ø¨Ù†Ø¬Ø§Ø­")
        return proc, header_row, data_rows

    else:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        return pd.DataFrame(), header_row, data_rows

@st.cache_data(ttl=900)
def get_df(spreadsheet_id: str, worksheet_name: str):
    vals = get_all_values(spreadsheet_id, worksheet_name)
    return parse_sheet(vals)

# ---------------- AI Summary ----------------
def ai_summary(df: pd.DataFrame):
    try:
        base = df.drop(columns=["Month"], errors="ignore")
        if len(base) < 2:
            return "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©."
        last, prev = base.iloc[-1], base.iloc[-2]
        rev = [c for c in base.columns if c.lower().startswith("total revenues")]
        exp = [c for c in base.columns if c.lower().startswith("total expenses")]
        lines = []
        if rev and prev[rev[0]] != 0:
            change_rev = (last[rev].iloc[0] - prev[rev].iloc[0]) / prev[rev].iloc[0] * 100
            lines.append(f"- Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª: {change_rev:+.1f}%.")
        if exp and prev[exp].iloc[0] != 0:
            change_exp = (last[exp].iloc[0] - prev[exp].iloc[0]) / prev[exp].iloc[0] * 100
            lines.append(f"- Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª: {change_exp:+.1f}%.")
        best = base.pct_change().mean(numeric_only=True).idxmax()
        lines.append(f"- Ø£Ø¨Ø±Ø² Ù†Ù…Ùˆ: {best}.")
        return "\n".join(lines)
    except Exception:
        return "ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ø®Øµ."

# ---------------- UI ----------------
st.markdown("## ğŸ’¡ Ù„ÙˆØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©")

# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„ Ø£ÙˆÙ„Ø§Ù‹
if not SPREADSHEET_ID:
    st.warning("ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Spreadsheet ID Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©")
    st.stop()

try:
    ws_list = list_worksheets(SPREADSHEET_ID)
    if not ws_list:
        st.warning("ğŸ“­ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£ÙˆØ±Ø§Ù‚ ÙÙŠ Ø§Ù„Ù…Ù„Ù")
        st.info("""
        **Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:**
        1. ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„Ù…Ù„Ù Ù…Ø¹: amany-data-reader@amany-health-project.iam.gserviceaccount.com
        2. ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù€ Spreadsheet ID ØµØ­ÙŠØ­
        3. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£ÙˆØ±Ø§Ù‚ ÙÙŠ Ø§Ù„Ù…Ù„Ù
        """)
        st.stop()
        
    st.success(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(ws_list)} ÙˆØ±Ù‚Ø©")
    st.write("Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ù…ØªØ§Ø­Ø©:", ws_list)
    
except Exception as e:
    st.error(f"âŒ ØªØ¹Ø°Ø± Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù")
    st.error(f"Ø§Ù„Ø®Ø·Ø£: {e}")
    st.info("""
    **Ø®Ø·ÙˆØ§Øª Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:**
    1. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØµØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª
    2. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Spreadsheet ID
    3. ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø±ÙƒØ© ÙÙŠ Google Sheets
    4. ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ ÙÙŠ secrets.toml
    """)
    st.stop()

sheet_name = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„ÙˆØ±Ù‚Ø©:", ws_list)

try:
    df_full, header_raw, rows_raw = get_df(SPREADSHEET_ID, sheet_name)
    if df_full.empty:
        st.warning(f"Ù„Ø§ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ§Ù„Ø­Ø© ÙÙŠ Ø§Ù„ÙˆØ±Ù‚Ø©: {sheet_name}")
        st.stop()
except Exception as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
    st.stop()

# Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù…Ø¹ Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙƒÙˆØ¯...
min_d, max_d = df_full.index.min().date(), df_full.index.max().date()
start_d, end_d = st.date_input("Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ:", value=(min_d, max_d), min_value=min_d, max_value=max_d)
df_f = df_full.loc[pd.to_datetime(start_d):pd.to_datetime(end_d)].copy()
if df_f.empty:
    st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ù…Ø­Ø¯Ø¯.")
    st.stop()

now_dt = now_cairo()
pm_end = prev_month_end(now_dt)

tab_raw, tab_proc = st.tabs(["ğŸ“„ Raw as-is", "ğŸ“Š Processed + KPIs"])

with tab_raw:
    all_vals = get_all_values(SPREADSHEET_ID, sheet_name)
    if all_vals:
        row1 = all_vals[0] if len(all_vals) > 0 else []
        row2 = all_vals[1] if len(all_vals) > 1 else []
        row3 = all_vals[2] if len(all_vals) > 2 else []
        safe_cols = resolve_headers_merged(row1, row2, row3)
        st.dataframe(pd.DataFrame(rows_raw, columns=safe_cols))
    else:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§Ù… Ù„Ø¹Ø±Ø¶Ù‡Ø§")

with tab_proc:
    st.caption(f"Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø£Ø¯Ù†Ø§Ù‡ Ø­ØªÙ‰ Ù†Ù‡Ø§ÙŠØ©: {pm_end.strftime('%b %Y')}")
    kpi_base = df_f.loc[:pm_end] if not df_f.loc[:pm_end].empty else df_f.copy()
    st.info(ai_summary(kpi_base))

    display_df = df_f.loc[:pm_end].reset_index().rename(columns={"__MonthDate__": "Date"})
    if display_df.empty:
        display_df = df_f.reset_index().rename(columns={"__MonthDate__": "Date"})
    display_df = display_df[["Month"] + [c for c in display_df.columns if c != "Month"]]
    st.dataframe(display_df)

    totals_cfg = read_totals_list(SPREADSHEET_ID)
    all_cols = [c for c in df_f.columns if c != "Month"]
    totals = [c for c in all_cols if c in totals_cfg]
    avgs = [c for c in all_cols if c not in totals_cfg]

    df_kpi = kpi_base

    def render_kpi_cards(cols, title, is_avg):
        if not cols:
            return
        st.subheader(title)
        cols_area = st.columns(4)
        for i, c in enumerate(cols):
            s = df_kpi[c]
            if s.empty:
                continue
            main_val = s.mean() if is_avg else s.sum()
            max_val, min_val = s.max(), s.min()
            try:
                max_dt = s.idxmax().strftime('%b %Y')
                min_dt = s.idxmin().strftime('%b %Y')
            except Exception:
                max_dt, min_dt = "-", "-"
            avg_val = s.mean()
            last_val = s.iloc[-1]
            growth = ((last_val - avg_val) / avg_val * 100) if avg_val else 0.0
            up = last_val > avg_val
            arrow = "â†‘" if up else "â†“"
            color = "#00ff00" if up else "#ff4136"
            highlight = ("border:2px solid #00ff00" if abs(growth) >= ALERT_THRESHOLD and up
                         else "border:2px solid #ff4136" if abs(growth) >= ALERT_THRESHOLD else "")
            with cols_area[i % 4]:
                st.markdown(f"""
                <div style="background:#111;padding:10px;border-radius:10px;{highlight}">
                  <div style="color:#39ff14;font-weight:bold;text-align:center">{c}</div>
                  <div style="color:#39ff14;font-size:22px;font-weight:bold;text-align:center">{main_val:,.2f}</div>
                  <div style="color:#ddd;text-align:center">Ø£Ø¹Ù„Ù‰: {max_dt} ({max_val:,.2f})</div>
                  <div style="color:#ddd;text-align:center">Ø£Ù‚Ù„: {min_dt} ({min_val:,.2f})</div>
                </div>
                <div style="background:#1a1a1a;padding:8px;border-radius:8px;margin-top:6px;text-align:center">
                  <span style="color:{color};font-weight:bold">{last_val:,.2f}</span>
                  <span style="color:{color};font-weight:bold">{arrow}</span>
                  <span style="color:#ccc">{avg_val:,.2f}</span>
                  <div style="color:{color}">({growth:+.1f}%)</div>
                </div>
                """, unsafe_allow_html=True)

    render_kpi_cards(totals, "Ø¥Ø¬Ù…Ø§Ù„ÙŠØ§Øª (Sum)", is_avg=False)
    render_kpi_cards(avgs, "Ù…ØªÙˆØ³Ø·Ø§Øª (Average)", is_avg=True)

# ---------------- Same-sheet comparison ----------------
st.markdown("---")
st.subheader("ğŸ“ˆ Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¤Ø´Ø±Ø§Øª Ø¯Ø§Ø®Ù„ Ù†ÙØ³ Ø§Ù„ÙˆØ±Ù‚Ø©")
available_cols = [c for c in df_f.columns if c != "Month"]
sel_cols = st.multiselect("Ø§Ø®ØªØ± Ù…Ø¤Ø´Ø±Ø§Øª:", available_cols, default=available_cols[:min(3, len(available_cols))])
chart_type = st.radio("Ù†ÙˆØ¹ Ø§Ù„Ø±Ø³Ù…:", ["Line", "Bar"], horizontal=True, index=0)

fig_same = None
if sel_cols:
    df_plot = df_f.loc[:pm_end].copy()
    if df_plot.empty:
        df_plot = df_f.copy()
    fig_same = go.Figure()
    for c in sel_cols:
        if chart_type == "Line":
            fig_same.add_trace(go.Scatter(x=df_plot.index, y=df_plot[c], mode="lines+markers", name=c))
        else:
            fig_same.add_trace(go.Bar(x=df_plot.index, y=df_plot[c], name=c))
    fig_same.update_layout(title=f"Ø¯Ø§Ø®Ù„ Ù†ÙØ³ Ø§Ù„ÙˆØ±Ù‚Ø© (Ø­ØªÙ‰ {pm_end.strftime('%b %Y')})", paper_bgcolor="black", plot_bgcolor="black", font_color="white")
    st.plotly_chart(fig_same, use_container_width=True)
    if KALEIDO:
        if st.button("ğŸ“· Ø­ÙØ¸ PNG - Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ", key="png_same"):
            try:
                png_bytes = fig_same.to_image(format="png", scale=2)
                st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© (PNG)", png_bytes, "same_sheet.png", "image/png", key="dl_same")
            except Exception as e:
                st.warning(f"ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© Ø¹Ø¨Ø± kaleido: {e}")

# ---------------- Multi-sheet comparison ----------------
st.markdown("---")
st.subheader("ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø£ÙˆØ±Ø§Ù‚ Ù…ØªØ¹Ø¯Ø¯Ø©")
sel_sheets = st.multiselect("Ø§Ø®ØªØ± Ø£ÙˆØ±Ø§Ù‚:", ws_list, default=[sheet_name])
common_kpi = None
dfs_map = {}

if sel_sheets:
    common_cols = set(available_cols)
    for ws in sel_sheets:
        d, _, _ = get_df(SPREADSHEET_ID, ws)
        if not d.empty:
            dfs_map[ws] = d
            common_cols &= set([c for c in d.columns if c != "Month"])
    if common_cols:
        common_kpi = st.selectbox("Ø§Ù„Ù…Ø¤Ø´Ø±:", sorted(list(common_cols)))

fig_multi = None
if common_kpi:
    fig_multi = go.Figure()
    for ws, d in dfs_map.items():
        seg = d.loc[:pm_end].copy()
        if seg.empty:
            seg = d.copy()
        fig_multi.add_trace(go.Scatter(x=seg.index, y=seg[common_kpi], mode="lines+markers", name=ws))
    fig_multi.update_layout(title=f"{common_kpi} Ø¹Ø¨Ø± Ø£ÙˆØ±Ø§Ù‚ Ù…ØªØ¹Ø¯Ø¯Ø© (Ø­ØªÙ‰ {pm_end.strftime('%b %Y')})", paper_bgcolor="black", plot_bgcolor="black", font_color="white")
    st.plotly_chart(fig_multi, use_container_width=True)
    if KALEIDO:
        if st.button("ğŸ“· Ø­ÙØ¸ PNG - Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£ÙˆØ±Ø§Ù‚", key="png_multi"):
            try:
                png_bytes = fig_multi.to_image(format="png", scale=2)
                st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© (PNG)", png_bytes, "multi_sheets.png", "image/png", key="dl_multi")
            except Exception as e:
                st.warning(f"ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© Ø¹Ø¨Ø± kaleido: {e}")

# ---------------- Advanced: Correlation & Heatmap ----------------
st.markdown("---")
st.subheader("ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…")
tab_corr, tab_heat = st.tabs(["Correlation", "Heatmap"])

with tab_corr:
    if available_cols:
        xk = st.selectbox("X:", available_cols, key="corr_x")
        yk = st.selectbox("Y:", [c for c in available_cols if c != xk], index=0 if len(available_cols) < 2 else 1, key="corr_y")
        df_corr = df_f.loc[:pm_end].copy()
        if df_corr.empty:
            df_corr = df_f.copy()
        corr = df_corr[xk].corr(df_corr[yk]) if xk and yk else np.nan
        st.metric("Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· (Pearson)", f"{corr:.2f}" if pd.notna(corr) else "N/A")
        if HAS_SM:
            figc = px.scatter(df_corr.reset_index(), x=xk, y=yk, trendline="ols", title=f"{xk} vs {yk} (Ø­ØªÙ‰ {pm_end.strftime('%b %Y')})")
        else:
            figc = px.scatter(df_corr.reset_index(), x=xk, y=yk, title=f"{xk} vs {yk} (Ø­ØªÙ‰ {pm_end.strftime('%b %Y')}, Ø¨Ø¯ÙˆÙ† OLS)")
        figc.update_layout(paper_bgcolor="black", plot_bgcolor="black", font_color="white")
        st.plotly_chart(figc, use_container_width=True)
        if KALEIDO:
            if st.button("ğŸ“· Ø­ÙØ¸ PNG - Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·", key="png_corr"):
                try:
                    st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© (PNG)", figc.to_image(format="png", scale=2), "correlation.png", "image/png", key="dl_corr")
                except Exception as e:
                    st.warning(f"ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© Ø¹Ø¨Ø± kaleido: {e}")

with tab_heat:
    hm_cols = st.multiselect("Ø§Ø®ØªØ± Ù…Ø¤Ø´Ø±Ø§Øª:", available_cols, default=available_cols[:min(12, len(available_cols))], key="hm_cols")
    if hm_cols:
        df_hm = df_f.loc[:pm_end].copy()
        if df_hm.empty:
            df_hm = df_f.copy()
        base = df_hm[hm_cols].copy()
        std = base.std().replace(0, np.nan)
        norm = (base - base.mean()) / std
        f = px.imshow(norm.T, text_auto=".2f", aspect="auto", color_continuous_scale="RdYlGn", title=f"Heatmap (z-score) Ø­ØªÙ‰ {pm_end.strftime('%b %Y')}")
        f.update_layout(paper_bgcolor="black", plot_bgcolor="black", font_color="white")
        st.plotly_chart(f, use_container_width=True)
        if KALEIDO:
            if st.button("ğŸ“· Ø­ÙØ¸ PNG - Ø§Ù„Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø­Ø±Ø§Ø±ÙŠØ©", key="png_heat"):
                try:
                    st.download_button("ØªÙ†Ø²ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© (PNG)", f.to_image(format="png", scale=2), "heatmap.png", "image/png", key="dl_heat")
                except Exception as e:
                    st.warning(f"ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø© Ø¹Ø¨Ø± kaleido: {e}")

# ---------------- Export ----------------
st.markdown("---")
exp_all = df_f.loc[:pm_end].reset_index().rename(columns={"__MonthDate__": "Date"})
if exp_all.empty:
    exp_all = df_f.reset_index().rename(columns={"__MonthDate__": "Date"})
exp_all = exp_all[["Month"] + [c for c in exp_all.columns if c != "Month"]]
st.download_button("ğŸ“¥ ØªØµØ¯ÙŠØ± CSV", exp_all.to_csv(index=False).encode("utf-8"), f"{sheet_name}.csv", "text/csv")

def to_excel_bytes(dfdict: dict):
    bio = BytesIO()
    engine = None
    try:
        import xlsxwriter  # noqa
        engine = "xlsxwriter"
    except Exception:
        try:
            import openpyxl  # noqa
            engine = "openpyxl"
        except Exception:
            engine = None

    if engine is None:
        import zipfile
        zbio = BytesIO()
        with zipfile.ZipFile(zbio, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
            for s, d in dfdict.items():
                csv_bytes = d.to_csv(index=False).encode("utf-8")
                zf.writestr(f"{s}.csv", csv_bytes)
        zbio.seek(0)
        return zbio.getvalue()

    with pd.ExcelWriter(bio, engine=engine) as w:
        for s, d in dfdict.items():
            sname = str(s)[:31]
            d.to_excel(w, index=False, sheet_name=sname)
    bio.seek(0)
    return bio.getvalue()

st.download_button("ğŸ“Š ØªØµØ¯ÙŠØ± Excel", to_excel_bytes({sheet_name: exp_all}),
                   f"{sheet_name}.xlsx",
                   "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
