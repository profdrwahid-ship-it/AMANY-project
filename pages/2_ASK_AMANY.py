# pages/3_ASK_AMANY.py
import streamlit as st
import pandas as pd
import gspread
import numpy as np
from google.oauth2.service_account import Credentials
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from io import BytesIO
import re

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="ASK AMANY - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'data_dict' not in st.session_state:
    st.session_state.data_dict = {}
if 'current_df' not in st.session_state:
    st.session_state.current_df = None
if 'current_sheet' not in st.session_state:
    st.session_state.current_sheet = None

# ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙØ­Ø©
st.markdown("""
<style>
    .main-header {
        text-align: center;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        color: white;
    }
    .assistant-message {
        background: #f0f8ff;
        padding: 1rem;
        border-radius: 10px;
        border-right: 5px solid #667eea;
        margin: 10px 0;
    }
    .user-message {
        background: #e6f7ff;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1890ff;
        margin: 10px 0;
    }
    .analysis-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        margin: 10px 0;
        border-left: 4px solid #52c41a;
    }
    .warning-card {
        background: #fffbe6;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #faad14;
        margin: 10px 0;
    }
    .success-card {
        background: #f6ffed;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #52c41a;
        margin: 10px 0;
    }
    .data-card {
        background: #f0f8ff;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #1890ff;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.markdown("""
<div class="main-header">
    <h1>ğŸ¤– ASK AMANY - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø§Ù„ÙŠ</h1>
    <p>Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø°ÙƒÙŠØ©</p>
</div>
""", unsafe_allow_html=True)

# ---------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ
# ---------------------------

class FinancialAnalyst:
    def __init__(self):
        self.analysis_types = {
            'ØªÙ‚Ø±ÙŠØ± Ø§Ø­ØµØ§Ø¦ÙŠ': self.generate_statistical_report,
            'Ù…Ù‚Ø§Ù„ ØªØ­Ù„ÙŠÙ„ÙŠ': self.generate_analytical_article,
            'Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©': self.generate_comparison_analysis,
            'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª': self.generate_trend_analysis,
            'ØªÙˆÙ‚Ø¹ Ù…Ø¨Ø³Ø·': self.generate_simple_forecast,
            'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡': self.generate_performance_analysis
        }
    
    def detect_data_frequency(self, df):
        """Ø§ÙƒØªØ´Ø§Ù ØªÙˆØ§ØªØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ÙŠÙˆÙ…ÙŠØŒ Ø´Ù‡Ø±ÙŠØŒ Ø³Ù†ÙˆÙŠ)"""
        date_columns = ['date', 'ØªØ§Ø±ÙŠØ®', 'month', 'Ø´Ù‡Ø±', 'year', 'Ø³Ù†Ø©']
        for col in df.columns:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in date_columns):
                try:
                    dates = pd.to_datetime(df[col], errors='coerce')
                    valid_dates = dates.dropna()
                    if len(valid_dates) > 1:
                        date_diff = (valid_dates.max() - valid_dates.min()).days
                        num_periods = len(valid_dates)
                        avg_days_between = date_diff / num_periods
                        
                        if avg_days_between <= 7:
                            return "ÙŠÙˆÙ…ÙŠ"
                        elif avg_days_between <= 35:
                            return "Ø´Ù‡Ø±ÙŠ"
                        else:
                            return "Ø³Ù†ÙˆÙŠ"
                except:
                    pass
        return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
    
    def detect_organization_type(self, sheet_name, columns):
        """Ø§ÙƒØªØ´Ø§Ù Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†Ø´Ø£Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø©"""
        sheet_lower = sheet_name.lower()
        columns_lower = [str(col).lower() for col in columns]
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ø³Ù… Ø§Ù„ÙˆØ±Ù‚Ø© ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø©
        healthcare_indicators = ['Ù…Ø³ØªØ´ÙÙ‰', 'Ø¹ÙŠØ§Ø¯Ø©', 'Ù…Ø±ÙŠØ¶', 'Ø·Ø¨ÙŠØ¨', 'Ø¹Ù„Ø§Ø¬', 'health', 'hospital', 'clinic', 'medical']
        retail_indicators = ['Ù…Ø¨ÙŠØ¹Ø§Øª', 'Ù…Ù†ØªØ¬', 'Ø¹Ù…ÙŠÙ„', 'Ù…ØªØ¬Ø±', 'sales', 'product', 'customer', 'revenue']
        service_indicators = ['Ø®Ø¯Ù…Ø©', 'Ø¹Ù…ÙŠÙ„', 'Ù…Ø´Ø±ÙˆØ¹', 'service', 'client', 'project']
        financial_indicators = ['Ù…ÙŠØ²Ø§Ù†ÙŠØ©', 'Ø±Ø¨Ø­', 'Ø®Ø³Ø§Ø±Ø©', 'Ù…ØµØ±ÙˆÙ', 'Ø¥ÙŠØ±Ø§Ø¯', 'budget', 'profit', 'loss', 'expense', 'income']
        
        if any(indicator in sheet_lower for indicator in healthcare_indicators) or \
           any(any(indicator in col for indicator in healthcare_indicators) for col in columns_lower):
            return "Ù…Ù†Ø´Ø£Ø© ØµØ­ÙŠØ©"
        elif any(indicator in sheet_lower for indicator in retail_indicators) or \
             any(any(indicator in col for indicator in retail_indicators) for col in columns_lower):
            return "Ù…Ù†Ø´Ø£Ø© ØªØ¬Ø§Ø±ÙŠØ©"
        elif any(indicator in sheet_lower for indicator in service_indicators) or \
             any(any(indicator in col for indicator in service_indicators) for col in columns_lower):
            return "Ù…Ù†Ø´Ø£Ø© Ø®Ø¯Ù…ÙŠØ©"
        elif any(indicator in sheet_lower for indicator in financial_indicators) or \
             any(any(indicator in col for indicator in financial_indicators) for col in columns_lower):
            return "Ù…Ù†Ø´Ø£Ø© Ù…Ø§Ù„ÙŠØ©"
        else:
            return "Ù…Ù†Ø´Ø£Ø© Ø¹Ø§Ù…Ø©"
    
    def generate_statistical_report(self, df, sheet_name, columns):
        """ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø¥Ø­ØµØ§Ø¦ÙŠ Ù…ÙØµÙ„"""
        try:
            report = []
            report.append(f"## ğŸ“Š Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ù„Ù€ {sheet_name}")
            report.append("")
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
            org_type = self.detect_organization_type(sheet_name, columns)
            frequency = self.detect_data_frequency(df)
            
            report.append(f"**Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†Ø´Ø£Ø©:** {org_type}")
            report.append(f"**ØªÙˆØ§ØªØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** {frequency}")
            report.append(f"**ÙØªØ±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** {len(df)} Ø³Ø¬Ù„")
            report.append(f"**Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª:** {len(columns)} Ù…Ø¤Ø´Ø±")
            report.append("")
            
            # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙˆØµÙÙŠØ©
            report.append("### ğŸ“ˆ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙˆØµÙÙŠØ©")
            
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            
            if len(numeric_columns) == 0:
                report.append("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                return "\n".join(report)
            
            for col in numeric_columns[:6]:  # Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 6 Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© ÙÙ‚Ø·
                if df[col].notna().sum() > 0:
                    report.append(f"#### ğŸ“‹ {col}")
                    report.append(f"- **Ø§Ù„Ù…ØªÙˆØ³Ø·:** {df[col].mean():,.2f}")
                    report.append(f"- **Ø§Ù„ÙˆØ³ÙŠØ·:** {df[col].median():,.2f}")
                    report.append(f"- **Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ:** {df[col].std():,.2f}")
                    report.append(f"- **Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù‚ØµÙˆÙ‰:** {df[col].max():,.2f}")
                    report.append(f"- **Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø¯Ù†ÙŠØ§:** {df[col].min():,.2f}")
                    report.append(f"- **Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ù‚ÙŠÙ…:** {df[col].sum():,.2f}")
                    report.append("")
            
            # Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
            report.append("### ğŸ¯ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (KPIs)")
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ù…ØµØ±ÙˆÙØ§Øª
            revenue_cols = [col for col in numeric_columns if any(word in str(col).lower() for word in ['Ø¥ÙŠØ±Ø§Ø¯', 'Ø±Ø¨Ø­', 'Ø¯Ø®Ù„', 'revenue', 'income', 'sales'])]
            expense_cols = [col for col in numeric_columns if any(word in str(col).lower() for word in ['Ù…ØµØ±ÙˆÙ', 'ØªÙƒÙ„ÙØ©', 'Ø®Ø³Ø§Ø±Ø©', 'expense', 'cost'])]
            
            if revenue_cols and expense_cols:
                total_revenue = df[revenue_cols[0]].sum()
                total_expense = df[expense_cols[0]].sum()
                profit = total_revenue - total_expense
                profit_margin = (profit / total_revenue * 100) if total_revenue > 0 else 0
                
                report.append(f"**Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª:** {total_revenue:,.2f}")
                report.append(f"**Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª:** {total_expense:,.2f}")
                report.append(f"**ØµØ§ÙÙŠ Ø§Ù„Ø±Ø¨Ø­:** {profit:,.2f}")
                report.append(f"**Ù‡Ø§Ù…Ø´ Ø§Ù„Ø±Ø¨Ø­:** {profit_margin:.1f}%")
            
            # Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡Ù‹
            report.append("### ğŸ† Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡Ù‹")
            growth_rates = {}
            for col in numeric_columns:
                if len(df[col]) > 1 and df[col].iloc[0] != 0:
                    growth = ((df[col].iloc[-1] - df[col].iloc[0]) / df[col].iloc[0] * 100)
                    growth_rates[col] = growth
            
            if growth_rates:
                top_3 = sorted(growth_rates.items(), key=lambda x: x[1], reverse=True)[:3]
                for col, growth in top_3:
                    report.append(f"- **{col}:** {growth:+.1f}%")
            
            return "\n".join(report)
        except Exception as e:
            return f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}"
    
    def generate_analytical_article(self, df, sheet_name, columns):
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù‚Ø§Ù„ ØªØ­Ù„ÙŠÙ„ÙŠ"""
        try:
            org_type = self.detect_organization_type(sheet_name, columns)
            frequency = self.detect_data_frequency(df)
            numeric_columns = df.select_dtypes(include=[np.number]).columns
            
            article = []
            article.append(f"# ğŸ“ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù€ {sheet_name}")
            article.append("")
            article.append(f"ØªÙ…Ø«Ù„ ÙˆØ±Ù‚Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª '{sheet_name}' Ø³Ø¬Ù„Ø§Ù‹ {frequency} Ù„Ø£Ø¯Ø§Ø¡ {org_type}ØŒ Ø­ÙŠØ« ØªÙˆÙØ± Ø±Ø¤Ù‰ Ù‚ÙŠÙ‘Ù…Ø© Ø­ÙˆÙ„ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø£Ø¯Ø§Ø¡ Ø®Ù„Ø§Ù„ {len(df)} ÙØªØ±Ø© Ø²Ù…Ù†ÙŠØ©.")
            article.append("")
            
            if len(numeric_columns) > 0:
                # ØªØ­Ù„ÙŠÙ„ Ø£ÙØ¶Ù„ ÙˆØ£Ø³ÙˆØ£ Ø§Ù„Ø£Ø¯Ø§Ø¡
                best_performer = None
                best_growth = -float('inf')
                worst_performer = None
                worst_growth = float('inf')
                
                for col in numeric_columns:
                    if len(df[col]) > 1 and df[col].iloc[0] != 0:
                        growth = ((df[col].iloc[-1] - df[col].iloc[0]) / df[col].iloc[0] * 100)
                        if growth > best_growth:
                            best_growth = growth
                            best_performer = col
                        if growth < worst_growth:
                            worst_growth = growth
                            worst_performer = col
                
                article.append("## ğŸ“ˆ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¨Ø§Ø±Ø²")
                if best_performer:
                    article.append(f"**Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ù†Ù…ÙˆØ§Ù‹:** {best_performer} Ø¨Ù†Ø³Ø¨Ø© Ù†Ù…Ùˆ Ù…Ø°Ù‡Ù„Ø© ØªØ¨Ù„Øº {best_growth:.1f}%")
                if worst_performer and worst_growth < 0:
                    article.append(f"**Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ø£ÙƒØ«Ø± ØªØ±Ø§Ø¬Ø¹Ø§Ù‹:** {worst_performer} Ø¨Ù†Ø³Ø¨Ø© ØªØ±Ø§Ø¬Ø¹ {worst_growth:.1f}%")
                article.append("")
                
                # Ø§Ù„ØªÙˆØµÙŠØ§Øª
                article.append("## ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©")
                article.append("1. **ØªØ¹Ø²ÙŠØ² Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©:** Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø¯Ø¹Ù… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªØ¸Ù‡Ø± Ù†Ù…ÙˆØ§Ù‹ Ù…Ø³ØªÙ…Ø±Ø§Ù‹ ÙˆØ²ÙŠØ§Ø¯Ø© Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± ÙÙŠÙ‡Ø§")
                article.append("2. **Ù…Ø¹Ø§Ù„Ø¬Ø© Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù:** Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ÙƒØ§Ù…Ù†Ø© ÙˆØ±Ø§Ø¡ ØªØ±Ø§Ø¬Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆÙˆØ¶Ø¹ Ø®Ø·Ø· ØªØ­Ø³ÙŠÙ†")
                article.append("3. **ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙƒÙØ§Ø¡Ø©:** Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø°Ø§Øª Ø§Ù„ØªÙ‚Ù„Ø¨Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ù„Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø£ÙØ¶Ù„ ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡")
                article.append("4. **Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ:** Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ ÙˆÙˆØ¶Ø¹ Ø£Ù‡Ø¯Ø§Ù ÙˆØ§Ù‚Ø¹ÙŠØ©")
                article.append("")
            
            article.append(f"*ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¢Ù„ÙŠØ§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø°ÙƒØ§Ø¡ AMANY Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ {len(df)} Ø³Ø¬Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª*")
            
            return "\n".join(article)
        except Exception as e:
            return f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ù„: {str(e)}"
    
    def generate_comparison_analysis(self, df, selected_columns):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©"""
        try:
            analysis = []
            analysis.append("## âš–ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª")
            analysis.append("")
            
            numeric_df = df[selected_columns].select_dtypes(include=[np.number])
            
            if len(numeric_df.columns) < 2:
                return "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…ÙˆØ¯ÙŠÙ† Ø±Ù‚Ù…ÙŠÙŠÙ† Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©"
            
            # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª
            analysis.append("### ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª")
            means = numeric_df.mean()
            for col in numeric_df.columns:
                analysis.append(f"- **{col}:** {means[col]:,.2f}")
            analysis.append("")
            
            # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ùˆ
            analysis.append("### ğŸ“ˆ Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ù†Ù…Ùˆ")
            for col in numeric_df.columns:
                if len(numeric_df[col]) > 1 and numeric_df[col].iloc[0] != 0:
                    growth = ((numeric_df[col].iloc[-1] - numeric_df[col].iloc[0]) / numeric_df[col].iloc[0] * 100)
                    trend = "ğŸ“ˆ" if growth > 0 else "ğŸ“‰" if growth < 0 else "â¡ï¸"
                    analysis.append(f"- {trend} **{col}:** {growth:+.1f}%")
            analysis.append("")
            
            # Ø§Ù„ØªÙˆØµÙŠØ§Øª
            analysis.append("### ğŸ’¡ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª ÙˆØ§Ù„ØªÙˆØµÙŠØ§Øª")
            max_mean_col = means.idxmax()
            min_mean_col = means.idxmin()
            
            analysis.append(f"- **Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø©:** {max_mean_col} (Ù…ØªÙˆØ³Ø·: {means[max_mean_col]:,.2f})")
            analysis.append(f"- **Ø§Ù„Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ù‚Ù„ Ù‚ÙŠÙ…Ø©:** {min_mean_col} (Ù…ØªÙˆØ³Ø·: {means[min_mean_col]:,.2f})")
            analysis.append("- **Ù†ØµÙŠØ­Ø© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©:** Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø°Ø§Øª Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ù†Ø®ÙØ¶Ø© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ ØªÙ…ÙŠØ² Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù…Ø±ØªÙØ¹Ø©")
            
            return "\n".join(analysis)
        except Exception as e:
            return f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}"
    
    def generate_trend_analysis(self, df, columns):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©"""
        try:
            analysis = []
            analysis.append("## ğŸ“… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ©")
            analysis.append("")
            
            numeric_columns = df[columns].select_dtypes(include=[np.number]).columns
            
            if len(numeric_columns) == 0:
                return "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª"
            
            analysis.append("### ğŸ“ˆ Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©")
            
            for col in numeric_columns[:4]:  # ØªØ­Ù„ÙŠÙ„ Ø£ÙˆÙ„ 4 Ø£Ø¹Ù…Ø¯Ø©
                if len(df[col]) > 2:
                    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ Ø§Ù„Ø¨Ø³ÙŠØ·
                    x = np.arange(len(df[col]))
                    y = df[col].values
                    slope = np.polyfit(x, y, 1)[0]
                    
                    trend = "ğŸ“ˆ ØªØµØ§Ø¹Ø¯ÙŠ" if slope > 0 else "ğŸ“‰ ØªÙ†Ø§Ø²Ù„ÙŠ" if slope < 0 else "â¡ï¸ Ù…Ø³ØªÙ‚Ø±"
                    trend_strength = "Ù‚ÙˆÙŠ" if abs(slope) > df[col].std() else "Ù…Ø¹ØªØ¯Ù„" if abs(slope) > df[col].std()/2 else "Ø¶Ø¹ÙŠÙ"
                    
                    analysis.append(f"- **{col}:** Ø§ØªØ¬Ø§Ù‡ {trend} ({trend_strength})")
            
            analysis.append("")
            analysis.append("### ğŸ’¡ ØªÙØ³ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            analysis.append("- **Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØµØ§Ø¹Ø¯ÙŠ:** ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ØªØ­Ø³Ù† ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡ over time")
            analysis.append("- **Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªÙ†Ø§Ø²Ù„ÙŠ:** Ù‚Ø¯ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø­Ø§Ø¬Ø© Ù„Ù„ØªØ¯Ø®Ù„ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡")
            analysis.append("- **Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ù…Ø³ØªÙ‚Ø±:** ÙŠØ¹ÙƒØ³ Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹ ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡")
            
            return "\n".join(analysis)
        except Exception as e:
            return f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª: {str(e)}"
    
    def generate_simple_forecast(self, df, column):
        """ØªÙˆÙ‚Ø¹ Ù…Ø¨Ø³Ø· Ù„Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©"""
        try:
            if column not in df.columns or not pd.api.types.is_numeric_dtype(df[column]):
                return "âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠ ØµØ§Ù„Ø­"
            
            analysis = []
            analysis.append(f"## ğŸ”® ØªÙˆÙ‚Ø¹ Ù…Ø¨Ø³Ø· Ù„Ù„Ù…Ø¤Ø´Ø±: {column}")
            analysis.append("")
            
            values = df[column].dropna()
            if len(values) < 3:
                return "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªÙˆÙ‚Ø¹ (ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ 3 Ù‚ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„)"
            
            # ØªÙˆÙ‚Ø¹ Ø¨Ø³ÙŠØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ
            last_value = values.iloc[-1]
            avg_growth = values.pct_change().mean()
            
            if pd.notna(avg_growth) and not np.isinf(avg_growth):
                forecast_1 = last_value * (1 + avg_growth)
                forecast_3 = last_value * (1 + avg_growth) ** 3
                
                analysis.append(f"**ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©:**")
                analysis.append(f"- Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©: {last_value:,.2f}")
                analysis.append(f"- Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ Ø§Ù„Ù…ØªÙˆØ³Ø·: {avg_growth:+.2%}")
                analysis.append(f"- Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª: {len(values)}")
                analysis.append("")
                
                analysis.append(f"**ğŸ”® Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª:**")
                analysis.append(f"- Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©: {forecast_1:,.2f}")
                analysis.append(f"- Ø¨Ø¹Ø¯ 3 ÙØªØ±Ø§Øª: {forecast_3:,.2f}")
                analysis.append("")
                
                analysis.append("ğŸ’¡ *Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ø§ ØªÙˆÙ‚Ø¹ Ù…Ø¨Ø³Ø· ÙˆÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§ÙØªØ±Ø§Ø¶ Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø­Ø§Ù„ÙŠ*")
                analysis.append("âš ï¸ *Ø§Ù„ØªØ­Ø°ÙŠØ±: Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ù‚Ø¯ ØªØ®ØªÙ„Ù Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹ÙˆØ§Ù…Ù„ Ø®Ø§Ø±Ø¬ÙŠØ©*")
            else:
                analysis.append("âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙˆÙ‚Ø¹ Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ù†Ù…Ø· Ù†Ù…Ùˆ ÙˆØ§Ø¶Ø­")
            
            return "\n".join(analysis)
        except Exception as e:
            return f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙˆÙ‚Ø¹: {str(e)}"
    
    def generate_performance_analysis(self, df, columns):
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            analysis = []
            analysis.append("## ğŸ¯ ØªØ­Ù„ÙŠÙ„ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡")
            analysis.append("")
            
            numeric_columns = df[columns].select_dtypes(include=[np.number]).columns
            
            if len(numeric_columns) == 0:
                return "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡"
            
            analysis.append("### ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ø§Ù„ÙŠ")
            
            for col in numeric_columns[:5]:
                values = df[col].dropna()
                if len(values) > 1:
                    current = values.iloc[-1]
                    previous = values.iloc[-2] if len(values) > 1 else values.iloc[0]
                    change = ((current - previous) / previous * 100) if previous != 0 else 0
                    
                    status = "ğŸŸ¢ ØªØ­Ø³Ù† ÙƒØ¨ÙŠØ±" if change > 10 else "ğŸŸ¡ ØªØ­Ø³Ù† Ø·ÙÙŠÙ" if change > 0 else "ğŸ”´ ØªØ±Ø§Ø¬Ø¹ Ø·ÙÙŠÙ" if change > -10 else "ğŸ”» ØªØ±Ø§Ø¬Ø¹ ÙƒØ¨ÙŠØ±"
                    analysis.append(f"- **{col}:** {current:,.2f} ({status} {change:+.1f}%)")
            
            analysis.append("")
            analysis.append("### ğŸ† Ø§Ù„ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡")
            
            # ØªØµÙ†ÙŠÙ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø­Ø³Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù‚ÙŠÙ…
            means = df[numeric_columns].mean()
            top_3 = means.nlargest(3)
            
            analysis.append("**Ø£Ø¹Ù„Ù‰ 3 Ù…Ø¤Ø´Ø±Ø§Øª Ø£Ø¯Ø§Ø¡:**")
            for col, value in top_3.items():
                analysis.append(f"- {col}: {value:,.2f}")
            
            return "\n".join(analysis)
        except Exception as e:
            return f"âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡: {str(e)}"

# ---------------------------
# Ø¯ÙˆØ§Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬ÙˆØ¬Ù„ Ø´ÙŠØªØ³
# ---------------------------

@st.cache_resource
def get_google_sheets_client():
    """Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø¬ÙˆØ¬Ù„ Ø´ÙŠØªØ³"""
    try:
        creds = Credentials.from_service_account_info(
            st.secrets["gcp_service_account"],
            scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"],
        )
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return None

@st.cache_data
def get_spreadsheet_data(_client, spreadsheet_id):
    """Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ø¨Ø±ÙŠØ¯Ø´ÙŠØª Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù…ÙƒØ±Ø±Ø©"""
    try:
        spreadsheet = _client.open_by_key(spreadsheet_id)
        worksheets = spreadsheet.worksheets()
        data_dict = {}
        
        for ws in worksheets:
            try:
                # Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø¯ÙŠÙ„Ø© Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… get_all_records
                all_data = ws.get_all_values()
                
                if len(all_data) > 0:
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù…ÙƒØ±Ø±Ø©
                    headers = all_data[0]
                    unique_headers = []
                    header_count = {}
                    
                    for header in headers:
                        header_str = str(header).strip() or "Column"
                        if header_str in header_count:
                            header_count[header_str] += 1
                            unique_headers.append(f"{header_str}_{header_count[header_str]}")
                        else:
                            header_count[header_str] = 1
                            unique_headers.append(header_str)
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ DataFrame ÙŠØ¯ÙˆÙŠØ§Ù‹
                    if len(all_data) > 1:
                        data_rows = all_data[1:]
                        df = pd.DataFrame(data_rows, columns=unique_headers)
                        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
                        for col in df.columns:
                            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='ignore')
                        data_dict[ws.title] = df
                    else:
                        data_dict[ws.title] = pd.DataFrame(columns=unique_headers)
                        
            except Exception as e:
                st.warning(f"ØªØ­Ø°ÙŠØ± ÙÙŠ ÙˆØ±Ù‚Ø© {ws.title}: {e}")
                continue
                
        return data_dict
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return {}

# ---------------------------
# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
# ---------------------------

def main():
    # Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ
    analyst = FinancialAnalyst()
    
    # Ù‚Ø³Ù… Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ”— Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        spreadsheet_id = st.text_input(
            "Ù…Ø¹Ø±Ù Ù…Ù„Ù Google Sheets:",
            value="1lELs2hhkOnFVix8HSE4iHpw8r20RXnEMXK9uzHSbT6Y",
            help="Ø£Ø¯Ø®Ù„ Ø§Ù„Ù€ Spreadsheet ID Ø§Ù„Ø®Ø§Øµ Ø¨Ù…Ù„ÙÙƒ"
        )
    
    with col2:
        st.subheader("âš¡ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª")
        load_data = st.button("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", type="primary", key="load_data")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if load_data and spreadsheet_id:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
            client = get_google_sheets_client()
            if client:
                data_dict = get_spreadsheet_data(client, spreadsheet_id)
                
                if data_dict:
                    st.session_state.data_loaded = True
                    st.session_state.data_dict = data_dict
                    st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(data_dict)} ÙˆØ±Ù‚Ø© Ø¨Ù†Ø¬Ø§Ø­")
                else:
                    st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ù…Ù„Ù")
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø­Ù…Ù„Ø©
    if st.session_state.data_loaded and st.session_state.data_dict:
        st.markdown("---")
        st.subheader("ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ù…ØªØ§Ø­Ø©
        sheets_list = list(st.session_state.data_dict.keys())
        selected_sheet = st.selectbox("ğŸ“„ Ø§Ø®ØªØ± Ø§Ù„ÙˆØ±Ù‚Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„:", sheets_list, key="sheet_selector")
        
        if selected_sheet:
            df = st.session_state.data_dict[selected_sheet]
            st.session_state.current_df = df
            st.session_state.current_sheet = selected_sheet
            
            st.markdown(f'<div class="data-card">'
                       f'ğŸ“‹ **Ø§Ù„ÙˆØ±Ù‚Ø©:** {selected_sheet} | '
                       f'ğŸ“Š **Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:** {len(df)} ØµÙ Ã— {len(df.columns)} Ø¹Ù…ÙˆØ¯ | '
                       f'ğŸ”¢ **Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©:** {len(df.select_dtypes(include=[np.number]).columns)}'
                       f'</div>', unsafe_allow_html=True)
            
            # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            with st.expander("ğŸ‘€ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", expanded=True):
                st.dataframe(df.head(10), use_container_width=True)
            
            # Ù‚Ø³Ù… Ø§Ù„ØªØ­Ù„ÙŠÙ„
            st.markdown("---")
            st.subheader("ğŸ¤– ØªØ­Ù„ÙŠÙ„ AMANY Ø§Ù„Ø°ÙƒÙŠ")
            
            # Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            analysis_type = st.selectbox(
                "Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„:",
                list(analyst.analysis_types.keys()),
                key="analysis_type"
            )
            
            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
            available_columns = df.columns.tolist()
            
            if analysis_type in ['Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡']:
                selected_columns = st.multiselect(
                    "Ø§Ø®ØªØ± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„:",
                    available_columns,
                    default=available_columns[:min(3, len(available_columns))],
                    key="column_selector"
                )
            elif analysis_type == 'ØªÙˆÙ‚Ø¹ Ù…Ø¨Ø³Ø·':
                selected_column = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù„Ù„ØªÙˆÙ‚Ø¹:", available_columns, key="forecast_column")
            else:
                selected_columns = available_columns
            
            # Ø²Ø± Ø§Ù„ØªÙ†ÙÙŠØ°
            if st.button("ğŸš€ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„", type="primary", key="run_analysis"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¨Ø¶Ø¹ Ø«ÙˆØ§Ù†Ù"):
                    try:
                        if analysis_type == 'ØªÙˆÙ‚Ø¹ Ù…Ø¨Ø³Ø·':
                            result = analyst.generate_simple_forecast(df, selected_column)
                        elif analysis_type in ['Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡']:
                            result = analyst.analysis_types[analysis_type](df, selected_columns)
                        else:
                            result = analyst.analysis_types[analysis_type](df, selected_sheet, available_columns)
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                        st.markdown("---")
                        st.markdown("### ğŸ“‹ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„")
                        st.markdown(f'<div class="analysis-card">{result}</div>', unsafe_allow_html=True)
                        
                        # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ±
                        st.download_button(
                            "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙƒÙ€ Ù†Øµ",
                            result,
                            file_name=f"ØªØ­Ù„ÙŠÙ„_{selected_sheet}_{analysis_type}.txt",
                            mime="text/plain",
                            key="download_report"
                        )
                        
                    except Exception as e:
                        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}")
        
        # Ù‚Ø³Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø°ÙƒÙŠØ©
        st.markdown("---")
        st.subheader("ğŸ’¬ Ø£Ø³Ø¦Ù„Ø© Ø°ÙƒÙŠØ© ÙÙˆØ±ÙŠØ©")
        
        col_q1, col_q2, col_q3 = st.columns(3)
        
        with col_q1:
            if st.button("ğŸ“ˆ Ø£ÙØ¶Ù„ Ù…Ø¤Ø´Ø± Ø£Ø¯Ø§Ø¡", key="best_kpi"):
                if st.session_state.current_df is not None:
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                        result = analyst.generate_performance_analysis(st.session_state.current_df, st.session_state.current_df.columns)
                        st.markdown(f'<div class="analysis-card">{result}</div>', unsafe_allow_html=True)
        
        with col_q2:
            if st.button("ğŸ”„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ØªØ¬Ø§Ù‡Ø§Øª", key="trend_analysis"):
                if st.session_state.current_df is not None:
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                        result = analyst.generate_trend_analysis(st.session_state.current_df, st.session_state.current_df.columns)
                        st.markdown(f'<div class="analysis-card">{result}</div>', unsafe_allow_html=True)
        
        with col_q3:
            if st.button("ğŸ¯ ØªÙ‚Ø±ÙŠØ± Ø¥Ø­ØµØ§Ø¦ÙŠ", key="stat_report"):
                if st.session_state.current_df is not None:
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                        result = analyst.generate_statistical_report(
                            st.session_state.current_df, 
                            st.session_state.current_sheet, 
                            st.session_state.current_df.columns
                        )
                        st.markdown(f'<div class="analysis-card">{result}</div>', unsafe_allow_html=True)
    
    else:
        st.info("ğŸ‘† ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø²Ø± Ø£Ø¹Ù„Ø§Ù‡")

if __name__ == "__main__":
    main()
